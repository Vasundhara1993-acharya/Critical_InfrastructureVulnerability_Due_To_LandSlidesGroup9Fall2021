# -*- coding: utf-8 -*-
"""Data_Science_EDA_Group_9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pCxVdz75Kg9SKF6mfjTFvTa6IV3SryRV
"""

import pandas as pd
import numpy as np

##############################Get the dataset from the drive########################################
!pip install PyDrive
import os
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

############get the file from the drive#########################
fileId = drive.CreateFile({'id':'1bAeNalXqQSueD-5_BgbF6vVTKA53zIT5'}) 
fileId.GetContentFile('merged.h5')

fileId = drive.CreateFile({'id':'1AI1I3DsYxyuNwaGvD0LLlcyA6dSgkfGy'}) 
fileId.GetContentFile('predicted_data.h5')

import pandas as pd
store=pd.HDFStore("predicted_data.h5")
print(store.info())
final_data=store.get("predicted")

print(final_data.columns)

grouped=final_data.groupby(['id'])

 final_data=pd.DataFrame(grouped)

print(final_data.head)

print(final_data["elevation"])

final_data=final_data.groupby("id")

print(final_data["landslide_prob"])

labels = ['Low', 'Medium', 'High']
final_data['final_column']=pd.cut(final_data.landslide_prob, bins=3,labels=labels) ##############Three different bins########### Low, Moderate, High

labels = ['Low', 'Medium', 'High']
final_data['precipitation_column1']=pd.cut(final_data.precipitation, bins=3,labels=labels)

labels = ['Low', 'Medium', 'High']
final_data['earthquake_column1']=pd.cut(final_data.energy, bins=3,labels=labels)

print(final_data.columns)

final_data.precipitation_column1.astype("category").cat.codes

final_data.earthquake_column1.astype("category").cat.codes

final_data.insert(10,'Precipitation_values',final_data.precipitation_column1.astype("category").cat.codes)

final_data.insert(11,'Energy_values',final_data.earthquake_column1.astype("category").cat.codes)

final_data.insert(12,'Landslide_Probabilities',final_data.final_column.astype("category").cat.codes)

print(final_data.columns)

final_data.to_hdf('Final_data.h5', key='Final', mode='w'

final_data.to_csv('final_data.csv')

from google.colab import drive

# Mount your Drive to the Colab VM.
drive.mount('/gdrive')

# Write the DataFrame to CSV file.
with open('/gdrive/My Drive/final.csv', 'w') as f:
  final_data.to_csv(f)

final_data.p_column1.astype("category").cat.codes

final_data = final_data.drop("precipitation_column1", axis=1)

final_data = final_data.drop("final_column", axis=1)

final_data = final_data.drop("earthquake_column1", axis=1)

import pandas as pd
store=pd.HDFStore("merged.h5")
print(store.info())
data=store.get("merged")

print(data.columns)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

import seaborn as sns
sns.set_style("whitegrid")

##################DATA CLEANING, HANDLING MISSING VALUES ########33
data.isnull().sum()
###########THIS RETURNED NONE. SO NO MISSING VALUES.

sns.boxplot(x=data['precipitation'])
plt.show

sns.boxplot(x=data['energy'])
plt.show

sns.boxplot(x=data['latitude'])
plt.show

sns.boxplot(x=data['longitude'])
plt.show

sns.boxplot(x=data['elevation'])
plt.show

sns.boxplot(x=data['slope'])
plt.show





sns.boxplot(x=data['slope'])
plt.show

Q1=data["slope"].quantile(0.25)

Q3=data["slope"].quantile(0.75)

IQR=Q3-Q1

low=Q1-1.5*IQR

high=Q3+1.5*IQR

low

high

out_low=(data["slope"]<low)
out_high=(data["slope"]>high)

len(data["slope"])-(len(data["slope"][out_low])+len(data["slope"][out_high]))

###########after the elimination of the outliers
data=data[~(out_low|out_high)]

sns.boxplot(x=data['slope'])
plt.show

sns.boxplot(x=data['precipitation'])
plt.show

Q1=data["precipitation"].quantile(0.25)
Q3=data["precipitation"].quantile(0.75)
IQR=Q3-Q1
low=Q1-1.5*IQR
high=Q3+1.5*IQR
out_low=(data["precipitation"]<low)
out_high=(data["precipitation"]>high)
###########after the elimination of the outliers
data=data[~(out_low|out_high)]

print(low)
print(high)

data["precipitation"].quantile(0.98)

sns.boxplot(x=data['precipitation'])
3plt.show

##################The code from here removes all the outliers from the dataset####################3
from scipy.stats.mstats import winsorize
main_data_pr=winsorize(data["precipitation"],(0.01,0.02))

data["precipitation"]=main_data_pr

sns.boxplot(x=data["precipitation"])
plt.show

sns.boxplot(x=data["energy"])
plt.show



main_data_slope=winsorize(data["slope"],(0.01,0.02))

data["slope"]=main_data_slope

sns.boxplot(x=data["slope"])
plt.show

main_data_ele=winsorize(data["elevation"],(0.01,0.02))

data["elevation"]=main_data_ele

sns.boxplot(x=data["elevation"])
plt.show



import numpy as np

main_data_energy=np.log(data["energy"])

data["energy"]=main_data_energy

sns.boxplot(x=data["energy"])
plt.show

import numpy as np

main_data_run=np.log(data["run"])

data["run"]=main_data_run



sns.boxplot(x=data["run"])
plt.show

sns.boxplot(x=data["latitude"])
plt.show()

sns.boxplot(x=data["longitude"])
plt.show()

print(len(data))

sns.boxplot(x=data["landslide_prob"])
plt.show()

###############Histogram plot of the target variable############3
import matplotlib.pyplot as plt

print(data['landslide_prob'].describe())
plt.figure(figsize=(9, 8))
#sns.distplot(data['Final_column'], color='g', bins=100, hist_kws={'alpha': 0.4});
data['Final_column'].value_counts(sort=False).plot.bar(rot=0)

#############Histogram plots of the numerical variables (Note: I have not eliminated run yet)###############
df_num = data.select_dtypes(include = ['float64', 'int64','float32'])
df_num.head()

#############Plot histogram of the numerical data########################
df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);

##############Pair plot to see if we can some pattern between the independant and dependant variable (correlation check)
for i in range(0, len(df_num.columns), 5):
    sns.pairplot(data=df_num,
                x_vars=df_num["slope"],
                y_vars=df_num['Final_column'])

sns.pairplot(data=data,
                x_vars=data["slope"],
                y_vars=data['Final_column'])



############################Numerical verification of the correlation of independant variavles with the target variable
corr = data.corr()
corr.style.background_gradient(cmap='coolwarm')

##############In the form of heatmap for further visualization################################3
import seaborn as sb
dataplot = sb.heatmap(data.corr(), cmap="YlGnBu", annot=True)
  
# displaying heatmap
plt.show()

###########################ALSO NOTE THAT FROM THE CORRELATION MATRIX ABOVE 
#THE SLOPE AND ELEVATION ARE HIGHLY CORRELATED. DOES THAT MEAN WE NEED TO ELIMINATE ONE OF THEM?
print(data.columns)

data['landslide_prob'].value_counts()

####################CATEGORIZATION BEGINS#############################

###################NICK TO MODIFY###################

data.landslide_prob.value_counts()

print(data["landslide_prob"])

labels = ['Low', 'Medium', 'High']
data['final_column']=pd.cut(data.landslide_prob, bins=3,labels=labels) ##############Three different bins########### Low, Moderate, High

data['bins']=pd.cut(data.landslide_prob, bins=3)

data['bins']



import matplotlib.pyplot as plt
plt.hist(data['final_column'], bins=3)





data.insert(10,'Final_column',data.final_column.astype("category").cat.codes)

data = data.drop('final_column', 1)

data = data.drop('bins', 1)

print(data.columns)

data.to_hdf('Final_data1.h5', key='Final', mode='w')



print(data["Final_column"])

print(data.loc[data["Final_column"]=="High"])

##############This code is for the conversion of the landslide probability to categories#########
min_value = data['landslide_prob'].min()
max_value = data['landslide_prob'].max()
print(min_value)
print(max_value)

import numpy as np
bins = np.linspace(min_value,max_value,4)
bins

lab

data['bins'] = pd.cut(data['landslide_prob'], bins=bins, labels=labels, include_lowest=True,duplicates='drop')

import matplotlib.pyplot as plt
plt.hist(data['bins'], bins=3)

bins = [0, 0.2, 0.5, 1]
data['new_col'] = pd.qcut(data['landslide_prob'], bins,precision=10,duplicates='drop')

print(data['new_col'])

#############To show the plotting I might have to categorize the probabilities to different categories###########33


#category = pd.cut(data.landslide_prob,bins=[0,0.05,0.5,1.9],labels=['Low','Moderate','High'])
data.insert(10,'Final',data["bins"])

print(data["Final"]=="Moderate")

print(data["landslide_prob"])

################qcut starts here##################################
data['landslide_prob'].describe()

data['landslide_prob'].value_counts()

pd.qcut(data['landslide_prob'], q=4,duplicates='drop')

result, bins = pd.qcut(
    data['slope'], 
    3,                  # A single number value
    retbins=True,duplicates='drop'
)

bins

pd.qcut(data['landslide_prob'], 3, precision=0,duplicates='drop')



####################CATEGORIZATION ENDS

###############Violin plot with the variables having higher correlation###############3
import matplotlib.pyplot as plt

sns.violinplot(x='Final_column',y='precipitation', data=data)
plt.show()

sns.violinplot(x='Final_column',y='slope', data=data)
plt.show()

sns.violinplot(x='Final_column',y='elevation', data=data)
plt.show()

sns.violinplot(x='Final_column',y='energy', data=data)
plt.show()

print(data.head())

data.final_column.astype("category").cat.codes

print(data.loc[data.final_column.astype("category").cat.codes==0])

print(data.columns)

data.to_hdf('Final_data.h5', key='Final', mode='w',format='t')

###########I wanted to see the trend in the precipitation versus the landslide_prob###############
data.groupby('precipitation')['landslide_prob'].median().plot()

data.isnull().sum()